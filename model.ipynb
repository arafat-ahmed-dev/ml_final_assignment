{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a29eb567",
   "metadata": {},
   "source": [
    "# Mobile Price Classification\n",
    "\n",
    "This notebook implements a complete Machine Learning pipeline for classifying mobile phone prices into different price ranges based on their specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffceb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7b52c",
   "metadata": {},
   "source": [
    "## 1. Data Loading (5 Marks)\n",
    "Load the chosen dataset into your environment and display the first few rows along with the shape to verify correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "train_data = pd.read_csv('mobile_price_classsification_train.csv')\n",
    "test_data = pd.read_csv('mobile_price_classsification_test1.csv')\n",
    "\n",
    "# Checking the shape\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "\n",
    "# First 5 rows\n",
    "print(\"\\nFirst 5 rows of training data:\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking target variable distribution\n",
    "print(\"Target variable (price_range) distribution:\")\n",
    "print(train_data['price_range'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973763e",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing (10 Marks)\n",
    "Perform and document at least 5 distinct preprocessing steps (e.g., handling missing values, encoding, scaling, outlier detection, feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d420d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Checking missing values\n",
    "print(\"Step 1: Checking missing values\")\n",
    "print(\"Missing values in training data:\", train_data.isnull().sum().sum())\n",
    "print(\"Missing values in test data:\", test_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Outlier detection using IQR method\n",
    "print(\"Step 2: Outlier detection\")\n",
    "\n",
    "def find_outliers(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower) | (data[column] > upper)]\n",
    "    return len(outliers)\n",
    "\n",
    "# Check outliers in numeric columns\n",
    "numeric_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols.remove('price_range')\n",
    "\n",
    "print(\"Outliers found in each column:\")\n",
    "for col in numeric_cols:\n",
    "    outlier_count = find_outliers(train_data, col)\n",
    "    if outlier_count > 0:\n",
    "        print(f\"{col}: {outlier_count} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f62cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature engineering - creating new features\n",
    "print(\"Step 3: Feature engineering\")\n",
    "train_data['total_camera'] = train_data['pc'] + train_data['fc']\n",
    "train_data['screen_size'] = train_data['sc_h'] * train_data['sc_w']\n",
    "train_data['pixels'] = train_data['px_height'] * train_data['px_width']\n",
    "train_data['battery_per_weight'] = train_data['battery_power'] / (train_data['mobile_wt'] + 1)\n",
    "\n",
    "# Same for test data\n",
    "test_data['total_camera'] = test_data['pc'] + test_data['fc']\n",
    "test_data['screen_size'] = test_data['sc_h'] * test_data['sc_w']\n",
    "test_data['pixels'] = test_data['px_height'] * test_data['px_width']\n",
    "test_data['battery_per_weight'] = test_data['battery_power'] / (test_data['mobile_wt'] + 1)\n",
    "\n",
    "print(\"New features created: total_camera, screen_size, pixels, battery_per_weight\")\n",
    "print(\"New shape:\", train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb735975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Checking encoding of categorical/binary columns\n",
    "print(\"Step 4: Checking encoding of categorical columns\")\n",
    "binary_cols = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']\n",
    "print(\"Binary columns are already encoded as 0 and 1:\")\n",
    "for col in binary_cols:\n",
    "    print(f\"{col}: {train_data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Splitting data for training and validation\n",
    "print(\"Step 5: Splitting data for training and validation\")\n",
    "X = train_data.drop('price_range', axis=1)\n",
    "y = train_data['price_range']\n",
    "\n",
    "# Remove id from test if exists\n",
    "if 'id' in test_data.columns:\n",
    "    test_data = test_data.drop('id', axis=1)\n",
    "\n",
    "# Train test split - use stratified split for balanced classes\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Validation set:\", X_val.shape)\n",
    "print(\"Data split done! (Scaling will be done in pipeline)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d07c17",
   "metadata": {},
   "source": [
    "## 3. Pipeline Creation (10 Marks)\n",
    "Construct a standard Machine Learning pipeline that integrates preprocessing and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de348b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline that integrates preprocessing and model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Preprocessing step: feature scaling\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=1))  # Model\n",
    "])\n",
    "\n",
    "print(\"Pipeline created with preprocessing and model integration:\")\n",
    "print(pipeline)\n",
    "print(\"\\nPipeline Steps:\")\n",
    "print(\"  1. scaler: StandardScaler - normalizes features to zero mean and unit variance\")\n",
    "print(\"  2. classifier: RandomForestClassifier - the classification model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78fb4e",
   "metadata": {},
   "source": [
    "## 4. Primary Model Selection (5 Marks)\n",
    "Choose a suitable algorithm and justify why this specific model was selected for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473fb4e",
   "metadata": {},
   "source": [
    "### Model Justification: Random Forest Classifier\n",
    "\n",
    "I am using **Random Forest Classifier** because:\n",
    "- It works well for classification problems with multiple classes\n",
    "- It can handle both numeric and categorical features\n",
    "- It is not sensitive to outliers\n",
    "- It gives good accuracy without much tuning\n",
    "- It can show which features are important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e5ca1",
   "metadata": {},
   "source": [
    "## 5. Model Training (10 Marks)\n",
    "Train your selected model using the training portion of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ecb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained!\")\n",
    "\n",
    "# Checking training accuracy\n",
    "train_acc = pipeline.score(X_train, y_train)\n",
    "print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': pipeline.named_steps['classifier'].feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 important features:\")\n",
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522bc95",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation (10 Marks)\n",
    "Apply Cross-Validation to assess robustness and report the average score with standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation on training data\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation scores for each fold:\")\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f\"Fold {i+1}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard deviation: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b429f",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning (10 Marks)\n",
    "Optimize your model using search methods displaying both the parameters tested and the best results found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to test (with regularization to prevent overfitting)\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 150],\n",
    "    'classifier__max_depth': [8, 10],\n",
    "    'classifier__min_samples_split': [5, 10],\n",
    "    'classifier__min_samples_leaf': [2, 4]\n",
    "}\n",
    "\n",
    "print(\"Parameters being tested (with regularization):\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"{param}: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search - only on training data to avoid data leakage\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\nBest cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a21e75",
   "metadata": {},
   "source": [
    "## 8. Best Model Selection (10 Marks)\n",
    "Select the final best-performing model based on the hyperparameter tuning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad352712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best model:\")\n",
    "print(best_model)\n",
    "\n",
    "# Get the classifier from pipeline\n",
    "best_classifier = best_model.named_steps['classifier']\n",
    "print(f\"\\nBest model settings:\")\n",
    "print(f\"n_estimators: {best_classifier.n_estimators}\")\n",
    "print(f\"max_depth: {best_classifier.max_depth}\")\n",
    "print(f\"min_samples_split: {best_classifier.min_samples_split}\")\n",
    "print(f\"min_samples_leaf: {best_classifier.min_samples_leaf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f980f5",
   "metadata": {},
   "source": [
    "## 9. Model Performance Evaluation (10 Marks)\n",
    "Evaluate the model on the test set and print comprehensive metrics suitable for the problem type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2755047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training vs validation accuracy to detect overfitting\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# Predictions on validation set\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Precision, recall, f1\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4afb0",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "Save the trained model as a pickle file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as pickle file\n",
    "with open('mobile_priced_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(\"Model saved as 'mobile_priced_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
